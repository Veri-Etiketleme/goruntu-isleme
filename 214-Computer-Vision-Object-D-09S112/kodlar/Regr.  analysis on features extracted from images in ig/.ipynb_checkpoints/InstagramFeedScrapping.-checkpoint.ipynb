{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Listening Group Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InstagramAPI import InstagramAPI\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from time import sleep\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a target Directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted previous folder\n"
     ]
    }
   ],
   "source": [
    "Folder_Name = 'images'\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(Folder_Name)\n",
    "    print(\"Deleted previous folder\")\n",
    "except OSError as e:\n",
    "    print(f'Error: {Folder_Name} : {e.strerror}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  images  Created \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(Folder_Name):\n",
    "    os.mkdir(Folder_Name)\n",
    "    print(\"Directory \" , Folder_Name ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , Folder_Name ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Creation of a login function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_instagram(username, password):\n",
    "    api = InstagramAPI(username, password)\n",
    "    api.login()\n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Define real unsername and password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercice, we created a fake account and later deleted it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request return 400 error!\n",
      "{'message': 'Looks like you requested to delete this account. You can learn more in the Help Center.', 'help_url': 'http://help.instagram.com/369387319858360', 'error_type': 'inactive user', 'buttons': [{'title': 'Appeal', 'action': 'go_to_helper_url', 'helper_url': 'http://help.instagram.com/369387319858360'}], 'status': 'fail'}\n"
     ]
    }
   ],
   "source": [
    "username = \"5145725669\"\n",
    "password = \"AmanVenky\"\n",
    "api = login_instagram(username,password) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Function to import pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_image(candidates):\n",
    "    candidate = {}\n",
    "    pixels = 0\n",
    "    for cand in candidates:\n",
    "        # pick the highest resolution one\n",
    "        res = cand['height']*cand['width']\n",
    "        if res > pixels:\n",
    "            pixels = res\n",
    "            candidate = cand\n",
    "    return candidate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Function to save the loaded pictures in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_from_candidate(url):\n",
    "    filename = ''\n",
    "    response = requests.get(url)\n",
    "    print (response)\n",
    "    # check the response status code, 200 means good\n",
    "    if response.status_code == 200: \n",
    "        filename = url.split(\"/\")[-1].split('?')[0]\n",
    "        with open('images/'+ filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "            print(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Function to include posts under each picture in the extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_their_posts(api, user_id):\n",
    "    '''Retrieve all posts from someone else's profile'''\n",
    "    images = []\n",
    "    has_more_posts = True\n",
    "    max_id= ''\n",
    "\n",
    "    while has_more_posts:\n",
    "        api.getUserFeed(user_id, maxid=max_id)\n",
    "        if api.LastJson['more_available'] is not True:\n",
    "            has_more_posts = False #stop condition\n",
    "\n",
    "        max_id = api.LastJson.get('next_max_id','')\n",
    "        for item in api.LastJson['items']:\n",
    "            if item[\"media_type\"] ==1 and 'image_versions2' in item.keys(): #corresponds to images type of content, we don't want videos here\n",
    "                candidate = get_largest_image(item['image_versions2']['candidates'])\n",
    "                filename = save_image_from_candidate(candidate['url'])\n",
    "                if filename != '':\n",
    "                    try:\n",
    "                        caption = item['caption']['text']\n",
    "                    except:\n",
    "                        caption =\"None\"\n",
    "                    try:\n",
    "                        likes = item['like_count']\n",
    "                    except:\n",
    "                        likes = 0\n",
    "                    try:\n",
    "                        comments = item['comment_count']\n",
    "                    except:\n",
    "                        comments = 0\n",
    "                    try:\n",
    "                        location = item['location'][\"name\"]\n",
    "                    except:\n",
    "                        location = \"Unknown\"\n",
    "                    try:\n",
    "                        publication_time = item['taken_at']\n",
    "                    except:\n",
    "                        publication = \"Unknown\"\n",
    "                    images.append((filename, caption,likes,comments,location,publication_time))\n",
    "                   # sleep(2)\n",
    "            elif item['media_type'] == 8 : #corresponds to carousels type of content\n",
    "                for carousel in item['carousel_media']:\n",
    "                ###We don't need videos in carousels\n",
    "                    if carousel['media_type'] == 1:\n",
    "                        candidate = get_largest_image(carousel['image_versions2']['candidates'])\n",
    "                        # get image \n",
    "                        filename = save_image_from_candidate(candidate['url'])\n",
    "                        if filename != '':\n",
    "                            # get status, save as tuple\n",
    "                            try:\n",
    "                                caption = item['caption']['text']\n",
    "                            except:\n",
    "                                caption =\"None\"\n",
    "                            try:\n",
    "                                likes = item['like_count']\n",
    "                            except:\n",
    "                                likes = 0\n",
    "                            try:\n",
    "                                comments = item['comment_count']\n",
    "                            except:\n",
    "                                comments = 0\n",
    "                            try:\n",
    "                                location = item['location'][\"name\"]\n",
    "                            except:\n",
    "                                location = \"Unknown\"\n",
    "                            try:\n",
    "                                publication_time = item['taken_at']\n",
    "                            except:\n",
    "                                publication = \"Unknown\"\n",
    "                            images.append((filename, caption,likes,comments,location,publication_time))\n",
    "        if has_more_posts:\n",
    "            print(str(len(images)) + ' posts retrieved so far...')\n",
    "\n",
    "    print('Total posts retrieved: ' + str(len(images)))\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Looks like you requested to delete this account. You can learn more in the Help Center.',\n",
       " 'help_url': 'http://help.instagram.com/369387319858360',\n",
       " 'error_type': 'inactive user',\n",
       " 'buttons': [{'title': 'Appeal',\n",
       "   'action': 'go_to_helper_url',\n",
       "   'helper_url': 'http://help.instagram.com/369387319858360'}],\n",
       " 'status': 'fail'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.LastJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieve posts from Cafe Osmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the user_id number from this website:\n",
    "https://thumbtube.com/instagram-user-id-finder#userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 4790789\n",
    "\n",
    "start = time.time()\n",
    "content_list = get_their_posts(api, user_id)\n",
    "\n",
    "# run the code\n",
    "end = time.time()\n",
    "\n",
    "elapsed = end - start\n",
    "print(elapsed)\n",
    "print(len(content_list))\n",
    "print(elapsed/len(content_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transfrom JSON to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list\n",
    "content_df = pd.DataFrame(content_list) \n",
    "content_df.columns =['name_of_file','caption','likes_count',\"comments_count\",\"location\",\"publication_time\"]\n",
    "content_df\n",
    "content_df.to_csv(\"images_extracted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Other useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Function to retrieve all posts from our own profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_posts(api):\n",
    "    '''Retrieve all posts from own profile'''\n",
    "    my_posts = []\n",
    "    has_more_posts = True\n",
    "    max_id= ''\n",
    "\n",
    "    while has_more_posts:\n",
    "        api.getSelfUserFeed(maxid=max_id)\n",
    "        if api.LastJson['more_available'] is not True:\n",
    "            has_more_posts = False #stop condition\n",
    "\n",
    "        max_id = api.LastJson.get('next_max_id','')\n",
    "        my_posts.extend(api.LastJson['items']) #merge lists\n",
    "        sleep(2) # slows down to avoid flooding\n",
    "\n",
    "        if has_more_posts:\n",
    "            print(str(len(my_posts)) + ' posts retrieved so far...')\n",
    "\n",
    "    print('Total posts retrieved: ' + str(len(my_posts)))\n",
    "    \n",
    "    return my_posts\n",
    "\n",
    "my_posts = get_my_posts(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Function to include hashtags for each picture during extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_from_hashtag(hashtag, num_images):\n",
    "    images = []\n",
    "    \n",
    "\n",
    "    if get_hashtag == False:\n",
    "        return images\n",
    "\n",
    "    for item in my_insta_api.LastJson['items']:\n",
    "        if item['media_type'] == 1 and 'image_versions2' in item.keys():\n",
    "            candidate = get_largest_image(item['image_versions2']['candidates'])\n",
    "            # get image \n",
    "            filename = save_image_from_candidate(candidate['url'])\n",
    "            if filename != '':\n",
    "                # get status, save as tuple\n",
    "                caption = item['caption']['text']\n",
    "                images.append((filename, caption))\n",
    "            if len(images) >= num_images:\n",
    "                break\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Function to include people who liked each picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_likers(api, my_posts):\n",
    "    '''Retrieve all likers on all posts'''\n",
    "    \n",
    "    likers = []\n",
    "    \n",
    "    print('wait %.1f minutes' % (len(my_posts)*2/60.))\n",
    "    for i in range(len(my_posts)):\n",
    "        m_id = my_posts[i]['id']\n",
    "        api.getMediaLikers(m_id)\n",
    "        \n",
    "        likers += [api.LastJson]\n",
    "        \n",
    "        # Include post_id in likers dict list\n",
    "        likers[i]['post_id'] = m_id\n",
    "        \n",
    "        sleep(2)\n",
    "    print('done')\n",
    "    \n",
    "    return likers\n",
    "\n",
    "\n",
    "likers = get_posts_likers(api, my_posts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Function to include all people who commented each picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_commenters(api, my_posts):\n",
    "    '''Retrieve all commenters on all posts '''\n",
    "    \n",
    "    commenters = []\n",
    "    \n",
    "    print('wait %.1f minutes' % (len(my_posts)*2/60.))\n",
    "    for i in range(len(my_posts)):\n",
    "        m_id = my_posts[i]['id']\n",
    "        api.getMediaComments(m_id)\n",
    "        \n",
    "        commenters += [api.LastJson]\n",
    "        \n",
    "        # Include post_id in commenters dict list\n",
    "        commenters[i]['post_id'] = m_id\n",
    "            \n",
    "        sleep(2)\n",
    "    print('done')\n",
    "    \n",
    "    return commenters\n",
    "\n",
    "commenters = get_posts_commenters(api, my_posts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 Function to convert the list of people who liked each picture in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posts_likers_to_df(likers):\n",
    "    '''Transforms likers list of dicts into pandas DataFrame'''\n",
    "    \n",
    "    # Normalize likers by getting the 'users' list and the post_id of each like\n",
    "    df_likers = json_normalize(likers, 'users', ['post_id'])\n",
    "    \n",
    "    # Add 'content_type' column to know the rows are likes\n",
    "    df_likers['content_type'] = 'like'\n",
    "    \n",
    "    return df_likers\n",
    "\n",
    "def posts_commenters_to_df(commenters):\n",
    "    '''Transforms commenters list of dicts into pandas DataFrame'''\n",
    "    \n",
    "    # Include username and full_name of commenter in 'comments' list of dicts\n",
    "    for i in range(len(commenters)):\n",
    "        if len(commenters[i]['comments']) > 0: # checks if there is any comment on the post\n",
    "            for j in range(len(commenters[i]['comments'])):\n",
    "                # Puts username/full_name one level up\n",
    "                commenters[i]['comments'][j]['username'] = commenters[i]['comments'][j]['user']['username']\n",
    "                commenters[i]['comments'][j]['full_name'] = commenters[i]['comments'][j]['user']['full_name']\n",
    "                \n",
    "    # Create DataFrame\n",
    "    # Normalize commenters to have 1 row per comment, and gets 'post_id' from parent \n",
    "    df_commenters = json_normalize(commenters, 'comments', 'post_id')\n",
    "    \n",
    "    # Get rid of 'user' column as we already handled it above\n",
    "    del df_commenters['user']\n",
    "    \n",
    "    return df_commenters\n",
    "\n",
    "df_likers = posts_likers_to_df(likers)\n",
    "df_commenters = posts_commenters_to_df(commenters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 Results of all functions mentionned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total posts: ' + str(len(my_posts)))\n",
    "print('---------')\n",
    "print('Total likes on profile: ' + str(df_likers.shape[0])) #shape[0] represents number of rows\n",
    "print('Distinct users that liked your posts: ' +str(df_likers.username.nunique())) # nunique() will count distinct values of a col\n",
    "print('---------')\n",
    "print('Total comments on profile: ' + str(df_comment.shape[0]))\n",
    "print('Distinct users that commented your posts: ' +str(df_comment.username.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 Dataframe visualization of results from functions mentionned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likers.username.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likers.username.value_counts()[:10].plot(kind='bar', title='Top 10 media likers', grid=True, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likers.username.value_counts()[:10].plot(kind='pie', title='Top 10 media likers distribution', autopct='%1.1f%%', figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commenters['username'].value_counts()[:10].plot(kind='bar', figsize=(12,6), title='Top 10 post commenters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts date from unix time to YYYY-MM-DD hh24:mm:ss\n",
    "df_commenters.created_at = pd.to_datetime(df_commenters.created_at, unit='s')\n",
    "df_commenters.created_at_utc = pd.to_datetime(df_commenters.created_at_utc, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commenters.created_at.dt.weekday.value_counts().sort_index().plot(kind='bar', figsize=(12,6), title='Comments per day of the week (0 - Sunday, 6 - Saturday)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commenters.created_at.dt.hour.value_counts().sort_index().plot(kind='bar', figsize=(12,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
