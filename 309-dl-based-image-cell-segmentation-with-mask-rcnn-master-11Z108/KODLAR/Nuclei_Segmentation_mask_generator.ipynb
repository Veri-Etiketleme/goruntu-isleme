{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Nuclei_Segmentation_mask_generator.ipynb","provenance":[{"file_id":"13G0YNIAJBXaGNvqsOCHbnsuqy5P1ut5f","timestamp":1581639723500}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fc8AKmmLtZP1","colab_type":"text"},"source":["Created on May 01, 2020\n","\n","@author:     Tim Schmittmann\n","\n","Description: Nuclei segmentation using Mask-RCNN based on https://github.com/ruchikaverma-iitg/Nuclei-Segmentation/blob/master/Nuclei_Segmentation_testing_code.ipynb\n","            \n"]},{"cell_type":"code","metadata":{"id":"k3exncFOtiVp","colab_type":"code","colab":{}},"source":["# For use in colab\n","# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8nTovX2trC4","colab_type":"code","colab":{}},"source":["# For use in colab. Adjust path depending on your setup \n","%cd /content/gdrive/My\\ Drive/informatik/privat/AML\\ Git/dl-based-image-cell-segmentation-with-mask-rcnn/\n","\n","!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWYjAzDXfMV1","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEQnn2UgtZP5","colab_type":"code","colab":{}},"source":["from PIL import Image\n","import skimage\n","import imageio\n","import os,sys\n","import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","#from PIL import Image\n","import scipy\n","import scipy.ndimage\n","from pathlib import Path\n","from skimage.measure import find_contours\n","from matplotlib.patches import Polygon\n","\n","# Import Mask RCNN and load my weights of my trained model. MRCNN is based on https://github.com/matterport/Mask_RCNN\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log\n","import nucleus\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSmrgmfvYyuH","colab_type":"code","colab":{}},"source":["# For cross-compatibility use pipreqs to save only required dependencies\n","!pip install pipreqs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpUrEKxPY3YJ","colab_type":"code","colab":{}},"source":["!pipreqs --force"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-gaPqf19XZTg","colab_type":"code","colab":{}},"source":["# In case pipreqs missed something\n","!pip freeze > pipfreeze.requirements.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N7sS9r52tZQF","colab_type":"code","colab":{}},"source":["# Dataset directory\n","ROOT_DIR = os.path.abspath(\"\")\n","WEIGHTS_DIR = os.path.join(ROOT_DIR, \"weights/\")\n","DATASET_DIR = os.path.join(ROOT_DIR, \"images/\")\n","RESULTS_DIR = os.path.join(ROOT_DIR, \"results/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m4EmIE38ZnVm","colab_type":"code","colab":{}},"source":["if not os.path.isdir(DATASET_DIR):\n","  os.mkdir(DATASET_DIR)\n","if not os.path.isdir(WEIGHTS_DIR):\n","  os.mkdir(WEIGHTS_DIR)\n","if not os.path.isdir(RESULTS_DIR):\n","  os.mkdir(RESULTS_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGMra1HxcTtA","colab_type":"code","colab":{}},"source":["\"\"\"Download weights file. Original: https://drive.google.com/drive/folders/16oPaebQnZCMzEsEGvhSVPMvEhbKJPATQ\n","   And move it to \"weights/mask_rcnn_weights.h5\"\n","   Sometimes the automatic download+unzip routine fails in colab and results in corrupt files. \n","   In that case simply download the originals and move the files into the correct directory.\n","\"\"\"\n","!wget -O weights.zip https://schmittmann.me/index.php/s/2DubYqV9pzs4ax8/download\n","!unzip weights.zip -d weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjI7UmgIZzno","colab_type":"code","colab":{}},"source":["\"\"\"Download and extract example dataset. \n","   Provided by Dr. Middeke https://cloudstore.zih.tu-dresden.de/index.php/s/FQ2bjHaj6tR2bmg/download\n","   Images are sorted into directories by their (estimated) magnification.\n","\"\"\"\n","!wget -O images.zip https://schmittmann.me/index.php/s/or393w0KtB8EQjV/download \n","!unzip images.zip -d images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nXXzJ0mtZQh","colab_type":"code","colab":{}},"source":["# Initialize Mask RCNN model with pretrained weights\n","config = nucleus.NucleusInferenceConfig()\n","config.display()\n","DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n","with tf.device(DEVICE):\n","    nmodel = modellib.MaskRCNN(mode=\"inference\",\n","                              model_dir=os.getcwd(),\n","                              config=config)\n","weights_path = os.path.join(WEIGHTS_DIR, \"mask_rcnn_weights.h5\")\n","nmodel.load_weights(weights_path, by_name=True)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"31msSnLUMssA","colab_type":"code","colab":{}},"source":["def img_to_tiles(img, target_tile_size):\n","  \"\"\"Split image in evenly sized tiles. Crops any leftover pixel that are not large enough for another tile\"\"\"\n","  S = target_tile_size\n","  return [img[x:x+S,y:y+S] for x in range(0,int(img.shape[0] / S) * S,S) for y in range(0,int(img.shape[1] / S) * S,S)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPdHbslFyrCK","colab_type":"code","colab":{}},"source":["def prepare_image(img, scale_factor):\n","  \"\"\"Simple image preparation for Mask RCNN model\"\"\"\n","  img = skimage.exposure.equalize_adapthist(img)\n","  img = skimage.exposure.adjust_log(img)\n","  img = skimage.transform.rescale(img, (scale_factor, scale_factor, 1))\n","  img = img * 255.0\n","  return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7JDkVxSsN7d","colab_type":"code","colab":{}},"source":["def make_results_type_magnification_dir(result_type, magnification):\n","  \"\"\"Helper function to create result directories\"\"\"\n","  results_type_dir = os.path.join(RESULTS_DIR, result_type)\n","  if not os.path.isdir(results_type_dir):\n","    os.mkdir(results_type_dir)\n","  results_type_magnification_dir = os.path.join(results_type_dir, str(int(magnification)))\n","  if not os.path.isdir(results_type_magnification_dir):\n","    os.mkdir(results_type_magnification_dir)\n","  return results_type_magnification_dir"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Sb9jChcqYSr","colab_type":"code","colab":{}},"source":["def save_figure_results(results_type, magnification, filename):\n","  \"\"\"Helper function to save figures and create necessary directories\"\"\"\n","  results_dir = make_results_type_magnification_dir(results_type, magnification)\n","  plt.savefig(os.path.join(results_dir, filename+'.png'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKPckplhOjKs","colab_type":"code","colab":{}},"source":["def save_segmented_cells(filename, magnification, results_type, segmented_cells):\n","  \"\"\"Loop all segmented and extracted cell patches and save them inside \n","  their specific results_type+magnification directory\"\"\"\n","  for i in range(len(segmented_cells)):\n","    cell = segmented_cells[i]\n","    results_dir = make_results_type_magnification_dir(results_type, magnification)\n","    \n","    plt.imsave(os.path.join(results_dir, filename+'_cell'+str(i)+'.png'), cell)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"antL7wZdhDuX","colab_type":"code","colab":{}},"source":["def save_cell_masks(filename, magnification, results_type_dir, original_tile, cell_masks):\n","  \"\"\"Loop all cell masks and extract the corresponding patches from the original tile. \n","  Save the patches inside the specific results_type+magnification directory\"\"\"\n","  cells = []\n","  for i in range(cell_masks.shape[2]):\n","    cell_mask = np.copy(original_tile)\n","    cell_mask[cell_masks[:,:,i] == 0] = 0\n","    cells.append(crop_image_only_outside(cell_mask))\n","  save_segmented_cells(filename, magnification, results_type_dir, cells)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qO1whNbjibY0","colab_type":"code","colab":{}},"source":["def rois_to_masks(rois, tile):\n","  \"\"\"Transforms boundary boxes in format [xmin, ymin, xmax, ymax] into binary masks with the shape of tile\"\"\"\n","    roi_masks = []\n","    for roi in rois:\n","      roi = roi.astype(int)\n","      roi_mask = np.zeros((tile.shape[0], tile.shape[1]))\n","      roi_mask[roi[0]:roi[2], roi[1]:roi[3]] = 1\n","      roi_masks.append(roi_mask)\n","    return roi_masks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrwLdEd0FlgP","colab_type":"code","colab":{}},"source":["def get_extended_cell_rois(results, original_tile, rescaled_rois):\n","  \"\"\"Extend cell rois by 1/4th of their size\"\"\"\n","  for roi in rescaled_rois:\n","    dx = int((roi[2] - roi[0]) / 4)\n","    dy = int((roi[3] - roi[1]) / 4)\n","    roi[0] -= dx\n","    roi[1] -= dy\n","    roi[2] += dx\n","    roi[3] += dy\n","  return rescaled_rois"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n5dCkRAbNg04","colab_type":"code","colab":{}},"source":["def unify_cell_roi_masks(tile, cell_roi_masks):\n","  \"\"\"Simple union of cell_roi_masks\"\"\"\n","  cell_roi_masks_union = np.zeros(tile.shape)\n","  for roi_mask in cell_roi_masks:\n","    cell_roi_masks_union[roi_mask == 1] = 1\n","  return cell_roi_masks_union\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcTvBG2VPJyO","colab_type":"code","colab":{}},"source":["def get_avg_foreground_color(tile, cell_roi_masks_union):\n","  \"\"\"Calculate average color of cell pixels in tile.\n","  \n","  Parameters\n","  ----------\n","  tile : ndarray\n","      The image to calculate foreground color from\n","  cell_roi_masks_union : ndarray\n","      Binary mask to identify cell pixels\n","      \n","  Returns\n","  -------\n","  foreground_color : ndarray\n","      Average rgb foreground color \n","  \"\"\"\n","  foreground = np.copy(tile)\n","  foreground = foreground[cell_roi_masks_union == 1]\n","\n","  foreground_color = np.average(foreground, axis=(0))\n","  return foreground_color"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2iIGuxmPOlX","colab_type":"code","colab":{}},"source":["def get_avg_background_color(tile, cell_roi_masks_union):\n","  \"\"\"Calculate artificial average background color of non-cell pixels in tile.\n","  To better separate background and foreground, we artificially increase the difference \n","  between foreground and background.\n","\n","  Parameters\n","  ----------\n","  tile : ndarray\n","      The image to calculate background color from\n","  cell_roi_masks_union : ndarray\n","      Binary mask to identify non-cell pixels\n","      \n","  Returns\n","  -------\n","  background_color : ndarray\n","      Enhanced average rgb background color \n","  \"\"\"\n","  background = np.copy(tile)\n","  background = background[cell_roi_masks_union == 0]\n","  background_color = np.average(background, axis=(0))\n","\n","  diff = background_color-get_avg_foreground_color(tile, cell_roi_masks_union)\n","  # Move background further away from foreground\n","  background_color += diff\n","  background_color = np.clip(background_color, 0,255)\n","  return background_color"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Wk36-bvzhDO","colab_type":"code","colab":{}},"source":["def crop_image_only_outside(img,tol=0):\n","    \"\"\"Crop image to remove all pixels below threshold/tolerance on the borders\n","    of the image (https://codereview.stackexchange.com/questions/132914/crop-black-border-of-image-using-numpy)\n","\n","    Parameters\n","    ----------\n","    img : ndarray\n","        Image to crop\n","    tol : int, optional\n","        Threshold. Crop any pixels on the borders of img below this. \n","\n","    Returns\n","    -------\n","    img : ndarray\n","        Cropped image\n","    \"\"\"\n","    mask = img>tol\n","    if img.ndim==3:\n","        mask = mask.all(2)\n","    m,n = mask.shape\n","    mask0,mask1 = mask.any(0),mask.any(1)\n","    col_start,col_end = mask0.argmax(),n-mask0[::-1].argmax()\n","    row_start,row_end = mask1.argmax(),m-mask1[::-1].argmax()\n","    return img[row_start:row_end,col_start:col_end]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGn9tAHTXQ-E","colab_type":"code","colab":{}},"source":["def get_segmented_cells_rois(tile, rescaled_masks, cell_roi_masks, cell_roi_masks_union, background_color):\n","  \"\"\"Extract the segmented cells as rectangular extraction from the original tile based on their roi_masks.\n","  Also uses the rescaled_masks to remove neighbouring cells from the final extracted patches.\n","\n","  Parameters\n","  ----------\n","  tile : ndarray\n","      The (original) tile to extract the rectangular cell images from\n","  rescaled_masks : ndarray\n","      Binary masks used to find neighbouring cells. Same shape as tile\n","  cell_roi_masks : ndarray\n","      The roi masks used to extract the rectangular cell images from tile\n","  cell_roi_masks_union : ndarray\n","      Union of all cell_roi_masks to quickly get all cell/non-cell pixels \n","  background_color : ndarray\n","      The average background color of non-cell pixels of tile\n","\n","  Returns\n","  -------\n","  cell_rois : ndarray\n","      Extracted the rectangular cell images from tile\n","  cell_rois_wo_neighbor : ndarray\n","      Extracted the rectangular cell images from tile with neighbouring cells replaced by background_color  \n","  \"\"\"\n","  img_homogenous_background = np.copy(tile)\n","  img_homogenous_background[cell_roi_masks_union == 0] = background_color\n","\n","  cell_rois_wo_neighbor = []\n","  cell_rois = []\n","  for i in range(len(cell_roi_masks)):\n","    mask = cell_roi_masks[i]\n","    if not mask.any(): \n","        continue;\n","    \n","    cell_roi = np.copy(img_homogenous_background)\n","    cell_roi[mask == 0] = 0\n","    cell_rois.append(crop_image_only_outside(cell_roi))\n","\n","    cell_roi_wo_neighbor = np.copy(img_homogenous_background)\n","\n","    for j in range(rescaled_masks.shape[2]):\n","\n","      if i != j:\n","        cell_roi_wo_neighbor[rescaled_masks[:,:,j].astype('int') > 0] = background_color\n","      \n","    cell_roi_wo_neighbor[mask == 0] = 0\n","    cell_rois_wo_neighbor.append(crop_image_only_outside(cell_roi_wo_neighbor))\n","  return (cell_rois, cell_rois_wo_neighbor)     \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYFSF2xvdMRw","colab_type":"code","colab":{}},"source":["def handle_dir(image_dir, target_magnification=10):\n","  \"\"\"Full pipeline to segment all images inside target directory into individual cells\"\"\"\n","\n","  print(image_dir)\n","  # extract magnification from directory name\n","  magnification = int(os.path.basename(image_dir))\n","\n","  images = glob.glob(os.path.join(image_dir,'*'))\n","  print(images)\n","\n","  \"\"\" The pretrained Mask RCNN model seens to works best with tiles of size 320x320px and a magnification of 10 (tested empirically).\n","  So we need to rescale all images of other magnifications and split them into tiles.\n","  E.g. to transform an image of size 2560x1920px with magnification of 60x into a tile of size 320x320px with magnification 10x,\n","  we would need to extract a tile of size 1920x1920px from the original image and downscale it with a factor of 10/60.\n","  \"\"\"\n","  target_tile_size = int(32 * target_magnification) \n","  scale_factor = target_magnification / magnification\n","  original_tile_size = int(target_tile_size / scale_factor)\n","\n","  for img_path in images:\n","    base_filename = Path(img_path).stem\n","    img = skimage.io.imread(img_path) #\n","    print(img_path)\n","    # First split the original image into the required tiles. E.g. 1920x1920px tile from above.\n","    original_tiles = np.array(img_to_tiles(img, original_tile_size))\n","\n","    for i in range(len(original_tiles)):\n","      filename = base_filename+'_tile'+str(i)\n","      original_tile = original_tiles[i]  \n","\n","      # Here we rescale our image to target size and do some more image preparation to improve segmentation\n","      augmented_tile = prepare_image(original_tile, scale_factor)\n","      # The model can be used on multiple images at once, but single processing makes saving the results and debugging easier \n","      results = nmodel.detect([augmented_tile], verbose=1)\n","      r = results[0]\n","      \"\"\"The Mask RCNN model returns two results for each segmented cell, which are useful for our purpose:\n","      1) Bounding boxes around the segmented cells called region of interest (r['rois']) in the shape [xmin, ymin, xmax, ymax]. \n","         r['rois'].shape == (nr_of_cells, 4)\n","      2) Binary masks (r['masks']) in the shape of the rescaled image. The last dimension of the nparray is for the segmented cells\n","       =>r['masks'].shape == (320, 320, nr_of_cells), with target_tile_size = 320 \n","      \"\"\"\n","      \n","      # Because we want to apply the segmentation results to our original image, \n","      # we need to scale back the results from our model \n","      rescaled_rois = r['rois'] * 1/scale_factor\n","      rescaled_masks = skimage.transform.rescale(r['masks'], (1/scale_factor, 1/scale_factor, 1))\n","\n","      _, ax = plt.subplots(1, figsize=(16,16))\n","      # Helper function from original Matterport repository to display Mask RCNN results\n","      # Visualize (and save) colored cell outline/boundaries inside original tile  \n","      visualize.display_instances(original_tile, rescaled_rois, rescaled_masks,r['class_ids'],['BG', 'Nuclei'],\n","                      ax=ax, show_mask=False, show_bbox=False,\n","                      title=\"Predictions\")  \n","      save_figure_results(\"tile_cells_outline\", magnification, filename)\n","\n","      # Visualize (and save) colored cell overlay/mask inside original tile  \n","      _, ax = plt.subplots(1, figsize=(16,16))\n","      visualize.display_instances(original_tile, rescaled_rois, rescaled_masks,r['class_ids'],['BG', 'Nuclei'],\n","                      ax=ax, show_mask=True, show_bbox=False,\n","                      title=\"Predictions\") \n","      save_figure_results(\"tile_cells_masked_dir\", magnification, filename)\n","       \n","      # Now we move away from visualizing the complete tile and instead display individual cells \n","      # First we transform the roi results into individual masks, which are still the size of the original tile   \n","      roi_masks = np.array(rois_to_masks(rescaled_rois, original_tile))\n","      roi_masks = np.moveaxis(roi_masks, 0, -1) # ((roi_masks.shape[2], roi_masks.shape[1], roi_masks.shape[0]))\n","      \n","      # Next we apply the individual cell masks to the original tile and save only the resulting segmented cells.\n","      # Here we save the individual cells as rectangular extraction the size of their roi from the original tile\n","      save_cell_masks(filename, magnification, 'cell_rois', original_tile, roi_masks)\n","      # Here we save the individual cells as extraction still the size of their roi from the orignal tile,\n","      # but now every pixel not segmented as cell is set to (0,0,0)\n","      save_cell_masks(filename, magnification, 'cell_masks', original_tile, rescaled_masks)\n","\n","      # Because the model is pretrained on nuclei, the results usually do not contain the whole cell. \n","      # Therefore the next step is extending the roi and repeating the above extraction from the original tile. \n","      extended_rois = get_extended_cell_rois(r, original_tile, rescaled_rois)\n","      rescaled_cell_roi_masks = rois_to_masks(extended_rois, original_tile)\n","      \n","      # Visualize (and save) rectangular extraction the size of their extended roi from the original tile\n","      _, ax = plt.subplots(1, figsize=(16,16))\n","      visualize.display_instances(original_tile, extended_rois, np.zeros(r['masks'].shape),r['class_ids'],['BG', 'Nuclei'],\n","                      ax=ax, show_mask=False, show_bbox=True,\n","                      title=\"Predictions\")  \n","      save_figure_results(\"tile_cells_extended_boxes\", magnification, filename)\n","      \n","      # When we extend the roi of each cell, we naturally start to create a stronger overlap between cells.\n","      # To prevent multiple cells in the same picture, for every cell we set all pixels belonging to other cells to \n","      # the average background color of all non-cell pixels (cell_rois_extended_wo_neighbors)\n","      rescaled_cell_roi_masks_union = unify_cell_roi_masks(original_tile, rescaled_cell_roi_masks)\n","      background_color = get_avg_background_color(original_tile, rescaled_cell_roi_masks_union)\n","      cell_rois_extended, cell_rois_extended_wo_neighbors = get_segmented_cells_rois(original_tile, rescaled_masks, rescaled_cell_roi_masks, rescaled_cell_roi_masks_union, background_color)\n","      # Here we save the individual cells as rectangular extraction the size of their extended roi from the orignal tile\n","      save_segmented_cells(filename, magnification, 'cell_rois_extended', cell_rois_extended)\n","      # Here we save the individual cells the same as \"cell_rois_extended\", but with neighbor cells replaced by \n","      # the average background color of all non-cell pixels (cell_rois_extended_wo_neighbors)\n","      save_segmented_cells(filename, magnification, 'cell_rois_extended_wo_neighbors', cell_rois_extended_wo_neighbors)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXMQVhdVoGRy","colab_type":"code","colab":{}},"source":["image_dirs=glob.glob(os.path.join(DATASET_DIR, \"*\"))\n","image_dirs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqvRQsgJxCKK","colab_type":"code","colab":{}},"source":["# Takes VERY long. You should try individual directories first. E.g. [image_dirs[0]]\n","for image_dir in image_dirs: \n","  target_magnification = 10\n","  handle_dir(image_dir, target_magnification)"],"execution_count":0,"outputs":[]}]}