{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import scipy.io as io\n",
    "from random import randrange \n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import cPickle as pickle\n",
    "import matplotlib\n",
    "from sklearn.feature_extraction import image\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(patches):\n",
    "    means_patches = mean(patches, axis=0)\n",
    "    std_patches = std(patches, axis=0)\n",
    "    patches = (patches - means_patches[np.newaxis,:])/(std_patches[np.newaxis,:])\n",
    "    return patches\n",
    "\n",
    "def whitening(patches):\n",
    "    eig_values, eig_vec = np.linalg.eig(np.cov(patches.T))\n",
    "    zca = eig_vec.dot(np.diag((eig_values+0.01)**-0.5).dot(eig_vec.T))\n",
    "    patches = np.dot(patches, zca)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ THE DATA\n",
    "with open(join('cifar-10-batches-py','data_batch_1'),'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "images = data['data'].reshape((-1,3,32,32)).astype('float64')\n",
    "images = np.rollaxis(images, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXTRACT RANDOM PATCHES\n",
    "rng = np.random.RandomState(0)\n",
    "NBPATCH = 16\n",
    "patches = np.zeros((NBPATCH*10000,6,6,3))\n",
    "indice =0\n",
    "for i in range(10000):\n",
    "    patches[indice:indice+NBPATCH] = image.extract_patches_2d(images[i], (6,6), NBPATCH, random_state=rng)\n",
    "    indice+=NBPATCH\n",
    "\n",
    "patches = patches.reshape(NBPATCH*10000,108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches = normalization(patches)\n",
    "patches = whitening(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run GMM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=100, covariance_type='full')\n",
    "gmm.fit(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# READ THE DATA / YOU CAN READ EITHER THE SAME BATCH OR AN OTHER\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "with open(join('cifar-10-batches-py','test_batch'),'rb') as f:\n",
    "    data_2 = pickle.load(f)\n",
    "\n",
    "data2 = data['data'].reshape((-1,3,32,32)).astype('float32')\n",
    "data2 = np.rollaxis(images, 1, 4)\n",
    "labels2 = data_2['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EXTRACT DETERMINIST PATCHES With STRIDE\n",
    "patch_size = 6\n",
    "s =1\n",
    "loss = 32-(patch_size+1)*(32/(patch_size+s))\n",
    "nb_patches = (32/(patch_size+s))\n",
    "patches = np.zeros((0,patch_size,patch_size,3))\n",
    "for x in range(0,32-loss,patch_size+s):\n",
    "    for y in range(0,32-loss,patch_size+s):\n",
    "        patches = np.concatenate((patches, images[:,x:x+patch_size,y:y+patch_size,:]), axis=0)\n",
    "\n",
    "patches = patches.reshape((patches.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REAPPLY THE SAME NORMALIZATION AND WHITENING\n",
    "patches = normalization(patches)\n",
    "patches = whitening(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newCls=gmm.predict(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRANSFORM THE PATCH TO BINARY VECTOR\n",
    "Kpatches=np.zeros((160000,NUM_CLUSTERS))\n",
    "for x in range(160000):\n",
    "    Kpatches[x][newCls[x]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONSTRUCT THE REPRESENTATION OF THE IMAGES USING THE BINARY VECTORS\n",
    "cls_images =np.zeros((10000,nb_patches, nb_patches,NUM_CLUSTERS))\n",
    "indices =0\n",
    "a,b =nb_patches,nb_patches\n",
    "for img in range(10000):\n",
    "    for i in range(nb_patches):\n",
    "        for j in range(nb_patches):\n",
    "            cls_images[img][i][j] = Kpatches[indices]\n",
    "            indices += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE THE FEATURES VECTORS THAT WILL BE USED IN NAIVE BAYES\n",
    "# WE WILL CLASSIFY THE FEATURES(REPRESENTATION OF THE IMAFE) NOT THE IMAGES \n",
    "\n",
    "nb_features = 4*NUM_CLUSTERS\n",
    "features = np.zeros((10000,nb_features))\n",
    "half = nb_patches/2\n",
    "\n",
    "for i in range(10000):\n",
    "    im = cls_images[i]\n",
    "    indice =0\n",
    "    for k in range(NUM_CLUSTERS):\n",
    "        features[i][indice]= sum(im[0:half,0:half,k])\n",
    "        features[i][indice+1]= sum(im[0:half,half:,k])\n",
    "        features[i][indice+2]= sum(im[half:,0:half,k])\n",
    "        features[i][indice+3]= sum(im[half:,half:,k])\n",
    "        indice+=4\n",
    "#Save the features to be used in Naive Bayes        \n",
    "pickle.dump(features, open(\"features/hard-k-150/raw-data/projecteatures-hard-300-16.obj\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
