# -*- coding: utf-8 -*-
"""proyecto_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJApdDHzfQmO-X8gAl7mffpWvAXpRAfW

LIBRERIAS
"""

!pip install git+git://github.com/PnS2019/pnslib.git

!pip install git+git://github.com/PnS2019/pnslib.git

import pandas as pd
import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from skimage.feature import hog
from skimage import data, exposure
from tensorflow import keras
import tensorflow as tf
from sklearn import metrics
from pnslib import utils
from tensorflow.keras.losses import categorical_crossentropy

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.datasets import make_blobs
from sklearn.preprocessing import MinMaxScaler

face_cascade = cv2.CascadeClassifier(
    utils.get_haarcascade_path('haarcascade_frontalface_default.xml'))
from scipy.spatial import distance

import os
from bs4 import BeautifulSoup
from keras.preprocessing.image import img_to_array,load_img
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix

histories = []

"""######DATOS TRAINING AND TEST"""

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'without_mask/'
y_mask = []
x_mask = []
y_no_mask = []
x_no_mask = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(50,50))
  x_no_mask.append(resized_img/255.0)
  y_no_mask.append(0)
print(np.shape(y_no_mask))

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(50,50))
  x_mask.append(resized_img/255.0)
  y_mask.append(1)
print(np.shape(y_mask))


x_mask = np.array(x_mask)
y_mask = np.array(y_mask)
x_no_mask = np.array(x_no_mask)
y_no_mask = np.array(y_no_mask)

x =  np.concatenate((x_no_mask,x_mask))
y = np.concatenate((y_no_mask,y_mask))
print('x',x.shape,'y',y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)
print('X_train:',X_train.shape)
print('X_test:',X_test.shape)
print('y_train:',y_train.shape)
print('y_test:',y_test.shape)

import tensorflow as tf
y_test = tf.keras.utils.to_categorical(y_test) #el one hot encoding
y_train = tf.keras.utils.to_categorical(y_train)

intervalos = range(min(y), max(y) + 2)
plt.hist(y,bins=intervalos, color='#F2AB6D', rwidth=0.85)
plt.xticks(intervalos)
plt.show()

"""DATOS VALIDATE"""

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/validation/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'no_mask/'
y_mask_validate = []
x_mask_validate = []
y_no_mask_validate = []
x_no_mask_validate = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(50,50))
  x_no_mask_validate.append(resized_img/255.0)
  y_no_mask_validate.append(0)
print(np.shape(y_no_mask_validate))
  

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in classes:
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(50,50))
  x_mask_validate.append(resized_img/255.0)
  y_mask_validate.append(1)
print(np.shape(x_mask_validate))

x_mask_validate = np.array(x_mask_validate)
y_mask_validate = np.array(y_mask_validate)
x_no_mask_validate = np.array(x_no_mask_validate)
y_no_mask_validate = np.array(y_no_mask_validate)

x_validate =  np.concatenate((x_no_mask_validate,x_mask_validate))
y_validate = np.concatenate((y_no_mask_validate,y_mask_validate))
print('x',x_validate.shape,'y',y_validate.shape)

intervalos = range(min(y_validate), max(y_validate) + 2)
plt.hist(y_validate,bins=intervalos, color='#F2AB6D', rwidth=0.85)
plt.xticks(intervalos)
plt.show()

"""##VALIDATE """

img_folder = '/content/drive/MyDrive/proyecto IA2/prueba_test/images/'
annot_folder = '/content/drive/MyDrive/proyecto IA2/prueba_test/annotations/'
desc = []
for dirname, _, filenames in os.walk(annot_folder):
    for filename in filenames:
        desc.append(os.path.join(dirname, filename))

img_name,label = [],[]

for d in desc:
    content = []
    n = []

    with open(d, "r") as file:
        content = file.readlines()
    content = "".join(content)
    soup = BeautifulSoup(content,"html.parser")
    file_name = soup.filename.string
    name_tags = soup.find_all("name")
    

    for t in name_tags:
        n.append(t.get_text())
        
    # slecting tag with maximum occurence in an image (If it has multiple tags)
    name = max(set(n), key = n.count)
  
    img_name.append(file_name)
    if (name == 'with_mask'):
      name = 1
      label.append(name)
    elif (name == 'mask_weared_incorrect'):
      name = 2
      label.append(name)
    elif (name == 'without_mask'):
      name = 0
      label.append(name)

labels = pd.get_dummies(label)
labels.head()

data, target = [],[]
img_h, img_w = 50, 50

for i in range(len(img_name)):
    
    name = img_name[i]
    path = img_folder + name
    

    img = cv2.imread(path)
    img = cv2.resize(img,(50,50))
    image = img/255.0

    # image = load_img(path, target_size = (img_h, img_w))
    # image = img_to_array(image)
    data.append(image)
    target.append(tuple(labels.iloc[i,:]))

data = np.array(data)
target = np.array(target)
print("data shapes : ",(data.shape))
print("target shapes : ",(target.shape))

array = np.array(label)
eliminar = np.where(array == 2)
print(eliminar)

data = np.delete(data, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 388, 400, 508, 521, 597, 681, 691, 815, 822, 832,370), axis=0)
target = np.delete(target, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 388, 400, 508, 521, 597, 681, 691, 815, 822, 832,370), axis=0)
print('eliminados')

array = np.array(target)
eliminar = np.where(array == 2)
print(eliminar)

target = np.delete(target,2,axis=1)

label = np.delete(label, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 388, 400, 508, 521, 597, 681, 691, 815, 822, 832,370), axis=0)

print("data shapes : ",(data.shape))
print("target shapes : ",(target.shape))

len(label)

intervalos = range(min(label), max(label) + 2)
plt.hist(label,bins=intervalos, color='#F2AB6D', rwidth=0.85)
plt.xticks(intervalos)
plt.show()

nuevo_array = label.tolist()
print(nuevo_array.count(1))
print(nuevo_array.count(0))

"""##RED NEURONAL CNN POR NOSOTROS"""

primer_modelo = tf.keras.models.Sequential()
primer_modelo.add(tf.keras.layers.Conv2D(200, (3, 3), activation='elu', padding='same', input_shape=(X_train.shape[1], X_train.shape[1], 3)))
primer_modelo.add(tf.keras.layers.BatchNormalization())
primer_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
primer_modelo.add(tf.keras.layers.Conv2D(100, (3, 3), activation='elu', kernel_initializer='glorot_normal', bias_initializer='glorot_normal', padding='same'))
primer_modelo.add(tf.keras.layers.MaxPooling2D((3, 3)))
primer_modelo.add(tf.keras.layers.BatchNormalization())
primer_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
primer_modelo.add(tf.keras.layers.Conv2D(100, (3, 3), activation='elu', kernel_initializer='glorot_normal', bias_initializer='glorot_normal', padding='same'))
primer_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
primer_modelo.add(tf.keras.layers.Flatten())
primer_modelo.add(tf.keras.layers.Dropout(0.5))
primer_modelo.add(tf.keras.layers.Dense(50, activation='elu'))
primer_modelo.add(tf.keras.layers.Dropout(0.2))
primer_modelo.add(tf.keras.layers.Dense(2, activation='softmax'))

primer_modelo.summary()

opt = tf.keras.optimizers.Adam()
primer_modelo.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])

datagen = ImageDataGenerator(
        featurewise_center=False,  
        samplewise_center=False,  
        featurewise_std_normalization=False,  
        samplewise_std_normalization=False,  
        zca_whitening=False,    
        rotation_range=25,    
        width_shift_range=0.1,
        height_shift_range=0.1,  
        horizontal_flip=True,  
        vertical_flip=False)
datagen.fit(X_train)

checkpoint_path = "/content/drive/MyDrive/proyecto IA2/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

histories.append(primer_modelo.fit(datagen.flow(X_train, y_train,seed=27,shuffle=False), epochs=20,verbose=1,
                    validation_data=(X_test, y_test),callbacks=[cp_callback]))

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(1, 2, 1)
ax.plot(histories[0].history['accuracy'], label='Train Accuracy');
ax.plot(histories[0].history['val_accuracy'], label='Validation Accuracy');
ax.set_xlabel('Epochs')
ax.set_ylabel('Accuracy');
ax.legend();
ax = fig.add_subplot(1, 2, 2)
ax.plot(histories[0].history['loss'], label='train loss');
ax.plot(histories[0].history['val_loss'], label='evaluation loss');
ax.legend();
ax.set_xlabel('Epochs');
ax.set_ylabel('Loss');

!ls {checkpoint_dir}

"""####Capas"""

layer_outputs = [layer.output for layer in primer_modelo.layers ]
activation_model = tf.keras.models.Model(inputs=primer_modelo.input, outputs=layer_outputs)
array = np.expand_dims(X_test[50], axis=0)
activations = activation_model.predict(array)
plt.figure(figsize=(20,3))
for i in range(32):
    plt.subplot(2,16,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(activations[0][0,:, :, i], cmap='viridis')

activation_model = tf.keras.models.Model(inputs=primer_modelo.input, outputs=layer_outputs)
array = np.expand_dims(X_test[50], axis=0)
activations = activation_model.predict(array)
plt.figure(figsize=(20,3))
for i in range(32):
    plt.subplot(2,16,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(activations[4][0,:, :, i], cmap='viridis')

"""####VALIDATION"""

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = primer_modelo.predict_classes(data)


for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

ynew.shape

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

"""##SEGUNDO MODELO - GRISES"""

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'without_mask/'
y_mask2 = []
x_mask2 = []
y_no_mask2 = []
x_no_mask2 = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  resized_img=cv2.resize(grayscale_img,(50,50))
  x_no_mask2.append(resized_img/255.0)
  y_no_mask2.append(0)
print(np.shape(y_no_mask2))

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  resized_img=cv2.resize(grayscale_img,(50,50))
  x_mask2.append(resized_img/255.0)
  y_mask2.append(1)
print(np.shape(y_mask2))


x_mask2 = np.array(x_mask2)
y_mask2 = np.array(y_mask2)
x_no_mask2 = np.array(x_no_mask2)
y_no_mask2 = np.array(y_no_mask2)

x2 =  np.concatenate((x_no_mask2,x_mask2))
y2 = np.concatenate((y_no_mask2,y_mask2))
print('x',x2.shape,'y',y2.shape)

from sklearn.model_selection import train_test_split
X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, random_state=0)
print('X_train:',X_train2.shape)
print('X_test:',X_test2.shape)
print('y_train:',y_train2.shape)
print('y_test:',y_test2.shape)

X_train2 = X_train2.reshape(-1, 50, 50, 1)
X_test2 = X_test2.reshape(-1, 50, 50, 1)

import tensorflow as tf
y_test2 = tf.keras.utils.to_categorical(y_test2) #el one hot encoding
y_train2 = tf.keras.utils.to_categorical(y_train2)

segundo_modelo = tf.keras.models.Sequential()
segundo_modelo.add(tf.keras.layers.Conv2D(200, (3, 3), activation='elu', padding='same', input_shape=(X_train2.shape[1], X_train2.shape[1], 1)))
segundo_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
segundo_modelo.add(tf.keras.layers.Conv2D(100, (3, 3), activation='elu', kernel_initializer='glorot_normal', bias_initializer='glorot_normal', padding='same'))
segundo_modelo.add(tf.keras.layers.MaxPooling2D((3, 3)))
segundo_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
segundo_modelo.add(tf.keras.layers.Conv2D(100, (3, 3), activation='elu', kernel_initializer='glorot_normal', bias_initializer='glorot_normal', padding='same'))
segundo_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
segundo_modelo.add(tf.keras.layers.Flatten())
segundo_modelo.add(tf.keras.layers.Dropout(0.5))
segundo_modelo.add(tf.keras.layers.Dense(50, activation='elu'))
segundo_modelo.add(tf.keras.layers.Dropout(0.2))
segundo_modelo.add(tf.keras.layers.Dense(2, activation='softmax'))

segundo_modelo.summary()

opt = tf.keras.optimizers.Adam(lr=0.001)
segundo_modelo.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])

histories.append(segundo_modelo.fit(datagen.flow(X_train2, y_train2,seed=27,shuffle=False), epochs=20,verbose=1,
                    validation_data=(X_test2, y_test2)))

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(1, 2, 1)
ax.plot(histories[1].history['accuracy'], label='Train Accuracy');
ax.plot(histories[1].history['val_accuracy'], label='Validation Accuracy');
ax.set_xlabel('Epochs');
ax.set_ylabel('Accuracy');
ax.legend();
ax = fig.add_subplot(1, 2, 2)

ax.plot(histories[1].history['loss'], label='train loss');
ax.plot(histories[1].history['val_loss'], label='evaluation loss');
ax.legend();
ax.set_xlabel('Epochs');
ax.set_ylabel('Loss');

"""###Capas"""

layer_outputs = [layer.output for layer in segundo_modelo.layers ]
activation_model = tf.keras.models.Model(inputs=segundo_modelo.input, outputs=layer_outputs)
array = np.expand_dims(X_test2[50], axis=0)
activations = activation_model.predict(array)
plt.figure(figsize=(20,3))
for i in range(32):
    plt.subplot(2,16,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(activations[0][0,:, :, i], cmap='viridis')

activation_model = tf.keras.models.Model(inputs=segundo_modelo.input, outputs=layer_outputs)
array = np.expand_dims(X_test2[50], axis=0)
activations = activation_model.predict(array)
plt.figure(figsize=(20,3))
for i in range(32):
    plt.subplot(2,16,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(activations[4][0,:, :, i], cmap='viridis')

"""###VALIDATION"""

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/validation/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'no_mask/'
y_mask_validate2 = []
x_mask_validate2 = []
y_no_mask_validate2 = []
x_no_mask_validate2 = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  resized_img=cv2.resize(grayscale_img,(50,50))
  x_no_mask_validate2.append(resized_img/255.0)
  y_no_mask_validate2.append(0)
print(np.shape(y_no_mask_validate2))
  

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in classes:
  img = cv2.imread(ruta_base + '/' + ruta)
  grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  resized_img=cv2.resize(grayscale_img,(50,50))
  x_mask_validate2.append(resized_img/255.0)
  y_mask_validate2.append(1)
print(np.shape(x_mask_validate))

x_mask_validate2 = np.array(x_mask_validate2)
y_mask_validate2 = np.array(y_mask_validate2)
x_no_mask_validate2 = np.array(x_no_mask_validate2)
y_no_mask_validate2 = np.array(y_no_mask_validate2)

data2, target2 = [],[]
img_h, img_w = 50, 50

for i in range(len(img_name)):
    
    name = img_name[i]
    path = img_folder + name
    

    img = cv2.imread(path)
    grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    img = cv2.resize(grayscale_img,(50,50))
    image = img/255.0

    # image = load_img(path, target_size = (img_h, img_w))
    # image = img_to_array(image)
    data2.append(image)
    target2.append(tuple(labels.iloc[i,:]))

data2 = np.array(data2)
target2 = np.array(target2)
print("data shapes : ",(data2.shape))
print("target shapes : ",(target2.shape))

data2 = np.delete(data2, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 400, 508, 521, 597, 681, 691, 815, 822, 832), axis=0)
target2 = np.delete(target2, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 400, 508, 521, 597, 681, 691, 815, 822, 832), axis=0)
print('eliminados')

data2 = data2.reshape(-1, 50, 50, 1)

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = segundo_modelo.predict_classes(data2)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

"""## Transfer Lerning

###RESNET 50
"""

model_A =  tf.keras.applications.ResNet50(input_shape=X_train[0].shape, weights='imagenet', include_top=False)
model_A.trainable = False
model_A.summary()

"""#### Sección nueva"""

model_A.trainable = True
print("Total ayers of Mobilenet: ", len(model_A.layers))
for layer in model_A.layers[10:50]:
  layer.trainable =  False
for layer in model_A.layers[100:170]:
  layer.trainable =  False
print(len(model_A.trainable_variables))

drop = tf.keras.layers.Dropout(0.5)
prediction_layer = tf.keras.layers.Dense(50,activation='tanh')
prediction_layer = tf.keras.layers.Dense(2, activation='softmax')
flatten_layer = tf.keras.layers.Flatten()
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

model_B_on_A = tf.keras.Sequential([
  model_A,
  global_average_layer,
  drop,
  prediction_layer
])

model_B_on_A.summary()

learning_rate= 0.0001

opt = tf.keras.optimizers.SGD(lr=learning_rate)
model_B_on_A.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])
histories.append(model_B_on_A.fit(datagen.flow(X_train, y_train, batch_size=50), epochs=20,verbose=1, batch_size=30,validation_data=(X_test, y_test)))

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(1, 2, 1)
ax.plot(histories[2].history['accuracy'], label='Train Accuracy');
ax.plot(histories[2].history['val_accuracy'], label='Validation Accuracy');
ax.set_xlabel('Epochs');
ax.set_ylabel('Accuracy');
ax.legend();
ax = fig.add_subplot(1, 2, 2)
ax.plot(histories[2].history['loss'], label='train loss');
ax.plot(histories[2].history['val_loss'], label='evaluation loss');
ax.legend();
ax.set_xlabel('Epochs');
ax.set_ylabel('Loss');

"""####VALIDATION"""

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = model_B_on_A.predict_classes(data)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

"""###VGG19"""

face_cascade = cv2.CascadeClassifier(
    utils.get_haarcascade_path('haarcascade_frontalface_default.xml'))

img = cv2.imread('/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/with_mask/with_mask_1539.jpg')
img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)
faces = face_cascade.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)
out_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

for (x,y,w,h) in faces:
    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)

vgg19 = tf.keras.applications.VGG19(weights='imagenet',include_top=False,input_shape=(50,50,3))

for layer in vgg19.layers:
    layer.trainable = False
    
model_vgg19 = tf.keras.models.Sequential()
model_vgg19.add(vgg19)
model_vgg19.add(tf.keras.layers.Flatten())
model_vgg19.add(tf.keras.layers.Dense(2,activation='sigmoid'))
model_vgg19.summary()

datagen = ImageDataGenerator(
        featurewise_center=False,  
        samplewise_center=False,  
        featurewise_std_normalization=False,  
        samplewise_std_normalization=False,  
        zca_whitening=False,    
        rotation_range=25,    
        width_shift_range=0.1,
        height_shift_range=0.1,  
        horizontal_flip=True,  
        vertical_flip=False)
datagen.fit(X_train)

model_vgg19.compile(optimizer="adam",loss="categorical_crossentropy",metrics ="accuracy")
histories.append(model_vgg19.fit_generator(datagen.flow(X_train, y_train, batch_size=50),
                    steps_per_epoch=X_train.shape[0]//50,
                    epochs=20,
                    verbose=1,
                    validation_data=(X_test, y_test)))

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(1, 2, 1)
ax.plot(histories[3].history['accuracy'], label='Train Accuracy');
ax.plot(histories[3].history['val_accuracy'], label='Validation Accuracy');
ax.set_xlabel('Epochs');
ax.set_ylabel('Accuracy');
ax.legend();
ax = fig.add_subplot(1, 2, 2)
ax.plot(histories[3].history['loss'], label='train loss');
ax.plot(histories[3].history['val_loss'], label='evaluation loss');
ax.legend();
ax.set_xlabel('Epochs');
ax.set_ylabel('Loss');

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = model_vgg19.predict_classes(data)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

"""###MOBILENET

####DATA
"""

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'without_mask/'
y_mask = []
x_mask = []
y_no_mask = []
x_no_mask = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(100,100))
  x_no_mask.append(resized_img/255.0)
  y_no_mask.append(0)
print(np.shape(y_no_mask))

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(100,100))
  x_mask.append(resized_img/255.0)
  y_mask.append(1)
print(np.shape(y_mask))


x_mask = np.array(x_mask)
y_mask = np.array(y_mask)
x_no_mask = np.array(x_no_mask)
y_no_mask = np.array(y_no_mask)

x =  np.concatenate((x_no_mask,x_mask))
y = np.concatenate((y_no_mask,y_mask))
print('x',x.shape,'y',y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)
print('X_train:',X_train.shape)
print('X_test:',X_test.shape)
print('y_train:',y_train.shape)
print('y_test:',y_test.shape)

import tensorflow as tf
y_test = tf.keras.utils.to_categorical(y_test) #el one hot encoding
y_train = tf.keras.utils.to_categorical(y_train)

img_folder = '/content/drive/MyDrive/proyecto IA2/prueba_test/images/'
annot_folder = '/content/drive/MyDrive/proyecto IA2/prueba_test/annotations/'
desc = []
for dirname, _, filenames in os.walk(annot_folder):
    for filename in filenames:
        desc.append(os.path.join(dirname, filename))

img_name,label = [],[]

for d in desc:
    content = []
    n = []

    with open(d, "r") as file:
        content = file.readlines()
    content = "".join(content)
    soup = BeautifulSoup(content,"html.parser")
    file_name = soup.filename.string
    name_tags = soup.find_all("name")
    

    for t in name_tags:
        n.append(t.get_text())
        
    # slecting tag with maximum occurence in an image (If it has multiple tags)
    name = max(set(n), key = n.count)
  
    img_name.append(file_name)
    if (name == 'with_mask'):
      name = 1
      label.append(name)
    elif (name == 'mask_weared_incorrect'):
      name = 2
      label.append(name)
    elif (name == 'without_mask'):
      name = 0
      label.append(name)

data, target = [],[]
img_h, img_w = 100, 100

for i in range(len(img_name)):
    
    name = img_name[i]
    path = img_folder + name
    

    img = cv2.imread(path)
    img = cv2.resize(img,(100,100))
    image = img/255.0

    # image = load_img(path, target_size = (img_h, img_w))
    # image = img_to_array(image)
    data.append(image)
    target.append(tuple(labels.iloc[i,:]))

data = np.array(data)
target = np.array(target)
print("data shapes : ",(data.shape))
print("target shapes : ",(target.shape))

labels.groupby([0]).count()

data = np.delete(data, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 400, 508, 521, 597, 681, 691, 815, 822, 832), axis=0)
target = np.delete(target, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 400, 508, 521, 597, 681, 691, 815, 822, 832), axis=0)
print('eliminados')

label = np.delete(label, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 400, 508, 521, 597, 681, 691, 815, 822, 832), axis=0)

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/validation/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'no_mask/'
y_mask_validate = []
x_mask_validate = []
y_no_mask_validate = []
x_no_mask_validate = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(100,100))
  x_no_mask_validate.append(resized_img/255.0)
  y_no_mask_validate.append(0)
print(np.shape(y_no_mask_validate))
  

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in classes:
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(100,100))
  x_mask_validate.append(resized_img/255.0)
  y_mask_validate.append(1)
print(np.shape(x_mask_validate))

x_mask_validate = np.array(x_mask_validate)
y_mask_validate = np.array(y_mask_validate)
x_no_mask_validate = np.array(x_no_mask_validate)
y_no_mask_validate = np.array(y_no_mask_validate)

x_validate =  np.concatenate((x_no_mask_validate,x_mask_validate))
y_validate = np.concatenate((y_no_mask_validate,y_mask_validate))
print('x',x_validate.shape,'y',y_validate.shape)

"""#####TRAIN"""

mobil = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=X_train[0].shape, weights='imagenet', include_top=False)

for layer in mobil.layers:
	layer.trainable = False
new_mobil = tf.keras.models.Sequential()
new_mobil.add(mobil)
new_mobil.add(tf.keras.layers.Flatten(name="flatten"))
new_mobil.add(tf.keras.layers.Dense(128, activation="relu"))
new_mobil.add(tf.keras.layers.Dropout(0.5))
new_mobil.add(tf.keras.layers.Dense(2, activation="softmax"))
new_mobil.summary()

INIT_LR = 1e-4
EPOCHS = 20
BS = 32
opt = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
new_mobil.compile(loss="binary_crossentropy", optimizer=opt,
	metrics=["accuracy"])

new_mobil.summary()

new_mobil.compile(optimizer="adam",loss="categorical_crossentropy",metrics ="accuracy")
histories.append(new_mobil.fit_generator(datagen.flow(X_train, y_train, batch_size=50),
                    steps_per_epoch=X_train.shape[0]//50,
                    epochs=20,
                    verbose=1,
                    validation_data=(X_test, y_test)))

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = new_mobil.predict_classes(data)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = np.argmax(new_mobil.predict(x_validate),axis=1)

for i in range(columns*rows):
    img = x_validate[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(y_validate[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(y_validate[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(y_validate, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

"""###DESNET 121"""

model_des = tf.keras.applications.DenseNet121(
                include_top=False, weights='imagenet', input_tensor=None,
                input_shape=None, pooling=None, classes=2
            )
model_des.trainable = False
model_des.summary()

model_des.trainable = True
print("Total ayers of Mobilenet: ", len(model_des.layers))
for layer in model_des.layers[10:150]:
  layer.trainable =  False
for layer in model_des.layers[300:310]:
  layer.trainable =  False
print(len(model_des.trainable_variables))

drop = tf.keras.layers.Dropout(0.5)
prediction_layer = tf.keras.layers.Dense(50,activation='tanh')
prediction_layer = tf.keras.layers.Dense(2, activation='softmax')
flatten_layer = tf.keras.layers.Flatten()
global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

model_B_on_des = tf.keras.Sequential([
  model_des,
  global_average_layer,
  drop,
  prediction_layer
])

model_B_on_des.summary()

learning_rate= 0.0001

opt = tf.keras.optimizers.SGD(lr=learning_rate)
model_B_on_des.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])
histories.append(model_B_on_des.fit(datagen.flow(X_train, y_train, batch_size=50), epochs=20,verbose=1, batch_size=30,validation_data=(X_test, y_test)))

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(1, 2, 1)
ax.plot(histories[5].history['accuracy'], label='Train Accuracy');
ax.plot(histories[5].history['val_accuracy'], label='Validation Accuracy');
ax.set_xlabel('Epochs');
ax.set_ylabel('Accuracy');
ax.legend();
ax = fig.add_subplot(1, 2, 2)
ax.plot(histories[5].history['loss'], label='train loss');
ax.plot(histories[5].history['val_loss'], label='evaluation loss');
ax.legend();
ax.set_xlabel('Epochs');
ax.set_ylabel('Loss');

"""######VALIDATION"""

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = model_B_on_des.predict_classes(data)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

"""#COMPARACION"""

histories

redes = ['CNN-1','CNN-grises','Resnet-50','VGG19','MobileNet','Desnet21']

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
for metric in histories[0].history:
    index = list(histories[0].history).index(metric)
    ax = axes.flatten()[index]
    layer_num = 0
    for history in histories:
        layer_num += 1
        ax.plot(history.history[metric], label=redes[layer_num-1])
    ax.set_title(metric)
    ax.legend()
plt.show()

"""##MULTIPLE FACES"""

new_mobil.save('new_mobil.h5')

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

import matplotlib.pyplot as plt
#trying it out on a sample image
img = cv2.imread('/content/drive/MyDrive/proyecto IA2/12415442-3x2-xlarge.jpg')

img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)

faces = face_cascade.detectMultiScale(img) #returns a list of (x,y,w,h) tuples

out_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image

#plotting
for (x,y,w,h) in faces:
    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),2)
plt.figure(figsize=(10,10))
plt.imshow(out_img)

mask_label = {0:'MASK',1:' NO MASK'}
dist_label = {0:(0,255,0),1:(255,0,0)}
MIN_DISTANCE = 200

if len(faces)>=2:
    label = [0 for i in range(len(faces))]
    for i in range(len(faces)-1):
        for j in range(i+1, len(faces)):
            dist = distance.euclidean(faces[i][:2],faces[j][:2])
            if dist<MIN_DISTANCE:
                label[i] = 1
                label[j] = 1
    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image
    for i in range(len(faces)):
        (x,y,w,h) = faces[i]
        crop = new_img[y:y+h,x:x+w]
        crop = cv2.resize(crop,(50,50))
        crop = np.reshape(crop,[1,50,50,3])/255.0
        mask_result = primer_modelo.predict(crop)
        cv2.putText(new_img,mask_label[mask_result.argmax()]+' '+str(round(np.max(mask_result),2)),(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)
        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)
    plt.figure(figsize=(10,10))
    plt.imshow(new_img)
            
else:
    print("No. of faces detected is less than 2")

"""#CONFIGURACIONES CON LAS MEJORES REDES"""

datasetPath = '/content/drive/MyDrive/proyecto IA2/self-built-masked-face-recognition-dataset/'
maskPath = datasetPath + 'with_mask/'
nonMaskPath = datasetPath + 'without_mask/'
y_mask = []
x_mask = []
y_no_mask = []
x_no_mask = []
iterador = 0


ruta_base = nonMaskPath
classes = os.listdir(nonMaskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(100,100))
  x_no_mask.append(resized_img/255.0)
  y_no_mask.append(0)
print(np.shape(y_no_mask))

ruta_base = maskPath
classes = os.listdir(maskPath)
for ruta in (classes):
  img = cv2.imread(ruta_base + '/' + ruta)
  resized_img=cv2.resize(img,(100,100))
  x_mask.append(resized_img/255.0)
  y_mask.append(1)
print(np.shape(y_mask))


x_mask = np.array(x_mask)
y_mask = np.array(y_mask)
x_no_mask = np.array(x_no_mask)
y_no_mask = np.array(y_no_mask)

x =  np.concatenate((x_no_mask,x_mask))
y = np.concatenate((y_no_mask,y_mask))
print('x',x.shape,'y',y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)
print('X_train:',X_train.shape)
print('X_test:',X_test.shape)
print('y_train:',y_train.shape)
print('y_test:',y_test.shape)

import tensorflow as tf
y_test = tf.keras.utils.to_categorical(y_test) #el one hot encoding
y_train = tf.keras.utils.to_categorical(y_train)

img_folder = '/content/drive/MyDrive/proyecto IA2/prueba_test/images/'
annot_folder = '/content/drive/MyDrive/proyecto IA2/prueba_test/annotations/'
desc = []
for dirname, _, filenames in os.walk(annot_folder):
    for filename in filenames:
        desc.append(os.path.join(dirname, filename))

img_name,label = [],[]

for d in desc:
    content = []
    n = []

    with open(d, "r") as file:
        content = file.readlines()
    content = "".join(content)
    soup = BeautifulSoup(content,"html.parser")
    file_name = soup.filename.string
    name_tags = soup.find_all("name")
    

    for t in name_tags:
        n.append(t.get_text())
        
    # slecting tag with maximum occurence in an image (If it has multiple tags)
    name = max(set(n), key = n.count)
  
    img_name.append(file_name)
    if (name == 'with_mask'):
      name = 1
      label.append(name)
    elif (name == 'mask_weared_incorrect'):
      name = 2
      label.append(name)
    elif (name == 'without_mask'):
      name = 0
      label.append(name)

data, target = [],[]
img_h, img_w = 100, 100

for i in range(len(img_name)):
    
    name = img_name[i]
    path = img_folder + name
    

    img = cv2.imread(path)
    img = cv2.resize(img,(100,100))
    image = img/255.0

    # image = load_img(path, target_size = (img_h, img_w))
    # image = img_to_array(image)
    data.append(image)
    target.append(tuple(labels.iloc[i,:]))

data = np.array(data)
target = np.array(target)
print("data shapes : ",(data.shape))
print("target shapes : ",(target.shape))

array = np.array(label)
eliminar = np.where(array == 2)
print(eliminar)

labels.groupby([0]).count()

data = np.delete(data, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 388, 400, 508, 521, 597, 681, 691, 815, 822, 832,370), axis=0)
target = np.delete(target, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 388, 400, 508, 521, 597, 681, 691, 815, 822, 832,370), axis=0)
print('eliminados')

label = np.delete(label, (73,  95,  96, 149, 158, 162, 197, 202, 224, 228, 238, 269, 344,
       355, 373, 388, 400, 508, 521, 597, 681, 691, 815, 822, 832,370), axis=0)

histories2 = []

"""#### PRIMER MODELO -V2"""

primer_modelo = tf.keras.models.Sequential()
primer_modelo.add(tf.keras.layers.Conv2D(200, (3, 3), activation='elu', padding='same', input_shape=(X_train.shape[1], X_train.shape[1], 3)))
primer_modelo.add(tf.keras.layers.BatchNormalization())
primer_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
primer_modelo.add(tf.keras.layers.Conv2D(100, (3, 3), activation='elu', kernel_initializer='glorot_normal', bias_initializer='glorot_normal', padding='same'))
primer_modelo.add(tf.keras.layers.MaxPooling2D((3, 3)))
primer_modelo.add(tf.keras.layers.BatchNormalization())
primer_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
primer_modelo.add(tf.keras.layers.Conv2D(100, (3, 3), activation='elu', kernel_initializer='glorot_normal', bias_initializer='glorot_normal', padding='same'))
primer_modelo.add(tf.keras.layers.MaxPooling2D((2, 2)))
primer_modelo.add(tf.keras.layers.Flatten())
primer_modelo.add(tf.keras.layers.Dropout(0.5))
primer_modelo.add(tf.keras.layers.Dense(50, activation='elu'))
primer_modelo.add(tf.keras.layers.Dropout(0.2))
primer_modelo.add(tf.keras.layers.Dense(2, activation='softmax'))

primer_modelo.summary()

opt = tf.keras.optimizers.Adam()
primer_modelo.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])

datagen = ImageDataGenerator(
        featurewise_center=False,  
        samplewise_center=False,  
        featurewise_std_normalization=False,  
        samplewise_std_normalization=False,  
        zca_whitening=False,    
        rotation_range=25,    
        width_shift_range=0.1,
        height_shift_range=0.1,  
        horizontal_flip=True,  
        vertical_flip=False)
datagen.fit(X_train)

checkpoint_path = "/content/drive/MyDrive/proyecto IA2/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

histories2.append(primer_modelo.fit(datagen.flow(X_train, y_train,seed=10,shuffle=False, batch_size=50), epochs=20,verbose=1,
                    validation_data=(X_test, y_test),callbacks=[cp_callback]))

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(1, 2, 1)
ax.plot(histories2[0].history['accuracy'], label='Train Accuracy');
ax.plot(histories2[0].history['val_accuracy'], label='Validation Accuracy');
ax.set_xlabel('Epochs')
ax.set_ylabel('Accuracy');
ax.legend();
ax = fig.add_subplot(1, 2, 2)
ax.plot(histories2[0].history['loss'], label='train loss');
ax.plot(histories2[0].history['val_loss'], label='evaluation loss');
ax.legend();
ax.set_xlabel('Epochs');
ax.set_ylabel('Loss');

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = primer_modelo.predict_classes(data)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

"""###MOBILENET-V2"""

mobil = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=X_train[0].shape, weights='imagenet', include_top=False)

for layer in mobil.layers:
	layer.trainable = False
new_mobil = tf.keras.models.Sequential()
new_mobil.add(mobil)
new_mobil.add(tf.keras.layers.Flatten(name="flatten"))
new_mobil.add(tf.keras.layers.Dense(128, activation="relu"))
new_mobil.add(tf.keras.layers.Dropout(0.5))
new_mobil.add(tf.keras.layers.Dense(2, activation="softmax"))
new_mobil.summary()

INIT_LR = 1e-4
EPOCHS = 20
BS = 20
opt = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)
new_mobil.compile(loss="binary_crossentropy", optimizer=opt,
	metrics=["accuracy"])

new_mobil.summary()

new_mobil.compile(optimizer="adam",loss="categorical_crossentropy",metrics ="accuracy")
histories2.append(new_mobil.fit_generator(datagen.flow(X_train, y_train,seed=10, batch_size=50),
                    steps_per_epoch=X_train.shape[0]//50,
                    epochs=20,
                    verbose=1,
                    validation_data=(X_test, y_test)))

fig = plt.figure(figsize=(12, 18))
columns = 4
rows = 5

# prep (x,y) for extra plotting
xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi
ys = np.abs(np.sin(xs))           # absolute of sine

# ax enables access to manipulate each of subplots
ax = []
porcentaje = 0
ynew = new_mobil.predict_classes(data)

for i in range(columns*rows):
    img = data[i]
    # create subplot and append to ax
    ax.append( fig.add_subplot(rows, columns, i+1) )
    if(label[i] == ynew[i] ):
      porcentaje += 1
    ax[-1].set_title("real="+str(label[i])+"\n predicción:"+str(ynew[i]))
    plt.imshow(img)

# do extra plots on selected axes/subplots
# note: index starts with 0
ax[2].plot(xs, 3*ys)
ax[19].plot(ys**2, xs)

probabilidad = metrics.accuracy_score(label, ynew)

print('PORCENTAJE PREDICCIÓN = '+ str(probabilidad))
print('\n')

plt.show()  # finally, render the plot

import pandas as pd
import seaborn as sn
import matplotlib.pyplot as plt

data = {'y_Actual':    label,
        'y_Predicted': ynew
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, annot=True)
plt.show()

from sklearn.metrics import confusion_matrix

confusion_matrix(label, ynew)

print(f1_score(label, ynew, average="macro"))
print(precision_score(label, ynew, average="macro"))
print(recall_score(label, ynew, average="macro"))

redes = ['CNN-1','MobileNet']

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
for metric in histories2[0].history:
    index = list(histories2[0].history).index(metric)
    ax = axes.flatten()[index]
    layer_num = 0
    for history in histories2:
        layer_num += 1
        ax.plot(history.history[metric], label=redes[layer_num-1])
    ax.set_title(metric)
    ax.legend()
plt.show()